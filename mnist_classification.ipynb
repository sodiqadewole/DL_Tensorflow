{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd015ad43e8cabc3ff3a26a19440a0ba8bfb4a549f1883b00904c587a5be32f00c8",
   "display_name": "Python 3.9.2 64-bit ('tensorflow_env': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "15ad43e8cabc3ff3a26a19440a0ba8bfb4a549f1883b00904c587a5be32f00c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train/255.0, x_test/255.0\n",
    "\n",
    "# Add channels dimension\n",
    "x_train = x_train[..., tf.newaxis].astype(\"float32\")\n",
    "x_test = x_test[..., tf.newaxis].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use tf.data to batch and shuffle\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).shuffle(10000).batch(32)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_test, y_test)).shuffle(10000).batch(32)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super (myModel, self).__init__()\n",
    "        self.conv1 = Conv2D(32, 3, activation='relu')\n",
    "        self.flatten = Flatten()\n",
    "        self.d1 = Dense(128, activation='relu')\n",
    "        self.d2 = Dense(10, activation='softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.d1(x)\n",
    "        return self.d2(x)\n",
    "\n",
    "model = myModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tf.GradientTape to train the model\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # training=True is only needed if there are layers with different\n",
    "        # behavior during training versus inference (e.g. Dropout).\n",
    "        predictions = model(images, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Test the Model\n",
    "@tf.function\n",
    "\n",
    "def test_step(images, labels):\n",
    "    # training = False is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout)\n",
    "    predictions = model(images, training=False)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1, Loss: 0.0015, Accuracy: 99.9550, Test Loss: 0.0978, Test Accuracy: 98.4900\n",
      "Epoch 2, Loss: 0.0020, Accuracy: 99.9317, Test Loss: 0.0997, Test Accuracy: 98.2400\n",
      "Epoch 3, Loss: 0.0022, Accuracy: 99.9233, Test Loss: 0.1094, Test Accuracy: 98.4700\n",
      "Epoch 4, Loss: 0.0011, Accuracy: 99.9700, Test Loss: 0.0968, Test Accuracy: 98.6000\n",
      "Epoch 5, Loss: 0.0028, Accuracy: 99.9117, Test Loss: 0.1043, Test Accuracy: 98.5100\n",
      "Epoch 6, Loss: 0.0014, Accuracy: 99.9567, Test Loss: 0.1412, Test Accuracy: 98.3100\n",
      "Epoch 7, Loss: 0.0019, Accuracy: 99.9400, Test Loss: 0.1144, Test Accuracy: 98.4700\n",
      "Epoch 8, Loss: 0.0016, Accuracy: 99.9517, Test Loss: 0.1570, Test Accuracy: 98.1600\n",
      "Epoch 9, Loss: 0.0017, Accuracy: 99.9533, Test Loss: 0.1246, Test Accuracy: 98.4000\n",
      "Epoch 10, Loss: 0.0003, Accuracy: 99.9850, Test Loss: 0.1489, Test Accuracy: 98.2300\n",
      "Epoch 11, Loss: 0.0010, Accuracy: 99.9750, Test Loss: 0.1229, Test Accuracy: 98.3200\n",
      "Epoch 12, Loss: 0.0014, Accuracy: 99.9617, Test Loss: 0.1352, Test Accuracy: 98.4600\n",
      "Epoch 13, Loss: 0.0013, Accuracy: 99.9650, Test Loss: 0.1466, Test Accuracy: 98.3800\n",
      "Epoch 14, Loss: 0.0032, Accuracy: 99.9233, Test Loss: 0.1400, Test Accuracy: 98.3900\n",
      "Epoch 15, Loss: 0.0009, Accuracy: 99.9667, Test Loss: 0.1450, Test Accuracy: 98.5500\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 15\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Reset the metrics at the start of the next epoch\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "\n",
    "    for images, labels in train_ds:\n",
    "        train_step(images, labels)\n",
    "\n",
    "    for test_images, test_labels in test_ds:\n",
    "        test_step(test_images, test_labels)\n",
    "\n",
    "    print(\n",
    "        f'Epoch {epoch + 1}, '\n",
    "        f'Loss: {train_loss.result():.4f}, '\n",
    "        f'Accuracy: {train_accuracy.result() * 100:.4f}, '\n",
    "        f'Test Loss: {test_loss.result():.4f}, '\n",
    "        f'Test Accuracy: {test_accuracy.result() * 100:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}